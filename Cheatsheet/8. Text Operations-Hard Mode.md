<div align="left">
  <h1> 8. Pandas Cheatsheet - Text Operations ( Hard Mode)

  ## Text Operations ( Hard Mode )

### 1. Build the sample Datasets : Data Generation

```py
import pandas as pd
import numpy as np
import random

# Seed for reproducibility
np.random.seed(42)
random.seed(42)

# --- Generate a large synthetic dataset ---
num_records = 10000 # Let's create 10,000 feedback entries

# Sample words for feedback
positive_words = ["excellent", "great", "awesome", "fantastic", "wonderful", "love", "satisfied"]
negative_words = ["bad", "poor", "terrible", "horrible", "disappointed", "slow", "buggy"]
neutral_words = ["ok", "average", "fine", "decent", "expected"]
product_words = ["service", "app", "website", "delivery", "product", "support", "feature"]

feedback_data = []

for i in range(num_records):
    user_id = f"user_{i+1:05d}"
    
    # Randomly choose sentiment for sentence construction
    sentiment_choice = random.choice(['positive', 'negative', 'neutral'])
    
    if sentiment_choice == 'positive':
        feedback_sentence = f"THE {random.choice(product_words).upper()} was {random.choice(positive_words).upper()}. VERY {random.choice(positive_words).upper()}!"
    elif sentiment_choice == 'negative':
        feedback_sentence = f"The {random.choice(product_words)} was {random.choice(negative_words)}. Very {random.choice(negative_words)}."
    else:
        feedback_sentence = f"The {random.choice(product_words)} was just {random.choice(neutral_words)}. nothing special."
        
    # Introduce random casing issues and leading/trailing spaces
    if random.random() < 0.3: # 30% chance of mixed case
        feedback_sentence = ''.join(random.choice([char.lower(), char.upper()]) for char in feedback_sentence)
    if random.random() < 0.2: # 20% chance of extra spaces
        feedback_sentence = "   " + feedback_sentence + "  "
    
    # Add some null values to simulate missing data
    if random.random() < 0.01: # 1% chance of null feedback
        feedback_sentence = np.nan

    feedback_data.append({
        'UserID': user_id,
        'FeedbackText': feedback_sentence,
        'Rating': random.randint(1, 5) # 1-5 star rating
    })

df = pd.DataFrame(feedback_data)

print(f"Original DataFrame head ({len(df)} records):")
print(df.head())
print("\nDataFrame Info (Note 'FeedbackText' dtype is 'object'):")
df.info()
print("-" * 30)
```
### 2. df.astype('string')
It adds the specified scalar value to every element within the DataFrame df.

```py
# Ensure the 'FeedbackText' column is of string type for .str accessor to work robustly
# Although often 'object' dtype works for strings, explicitly converting can be safer.
df['FeedbackText'] = df['FeedbackText'].astype('string')
print("\nAfter df['FeedbackText'].astype('string'):")
print(f"FeedbackText dtype: {df['FeedbackText'].dtype}")
print(df['FeedbackText'].head())
print("-" * 30)
```

### 3. df['column_name'].str.len()
It obtains the number of characters in the string values within columns.

```py
# Calculates the length of each string in the 'FeedbackText' column.
# Returns a Series of integers.
df['FeedbackLength'] = df['FeedbackText'].str.len()
print("\nAfter df['FeedbackText'].str.len():")
print(df[['FeedbackText', 'FeedbackLength']].head())
print(f"Average feedback length: {df['FeedbackLength'].mean():.2f}")
print("-" * 30)
```

### 4. Fill NaN values in 'FeedbackText'

```py
# Fill NaN values in 'FeedbackText' with an empty string temporarily for case conversions
# to avoid errors if a NaN is encountered, as .str methods propagate NaNs by default.
# We'll convert them back to None if needed, but for demonstration, we handle them.
df['CleanedFeedback'] = df['FeedbackText'].fillna('')
```

### 5. df['column_name'].str.lower()
It converts all strings in the column_name of the DataFrame df to lowercase.

```py
# Converts all characters in each string to lowercase.
df['FeedbackLower'] = df['CleanedFeedback'].str.lower()
print("\nAfter df['CleanedFeedback'].str.lower():")
print(df[['CleanedFeedback', 'FeedbackLower']].head())
print("-" * 30)
```

### 6. df['column_name'].str.upper()
It converts all strings in the column_name of the DataFrame df to uppercase.

```py
# Converts all characters in each string to uppercase.
df['FeedbackUpper'] = df['CleanedFeedback'].str.upper()
print("\nAfter df['CleanedFeedback'].str.upper():")
print(df[['CleanedFeedback', 'FeedbackUpper']].head())
print("-" * 30)
```
### 7. df['column_name'].str.title()
It returns a title-cased version of the string where every word starts with an uppercase character.

```py
# Converts the first character of each word to uppercase and the remaining to lowercase.
df['FeedbackTitle'] = df['CleanedFeedback'].str.title()
print("\nAfter df['CleanedFeedback'].str.title():")
print(df[['CleanedFeedback', 'FeedbackTitle']].head())
print("-" * 30)
```
### 8. df['column_name'].str.capitalize()
It returns only uppercases the first character of the entire string, regardless of the number of words present.

```py
# Converts the first character of the *entire string* to uppercase and the rest to lowercase.
df['FeedbackCapitalize'] = df['CleanedFeedback'].str.capitalize()
print("\nAfter df['CleanedFeedback'].str.capitalize():")
print(df[['CleanedFeedback', 'FeedbackCapitalize']].head())
print("-" * 30)
```
### 9. df['column_name'].str.swapcase()
It is used to convert every character in a string to a case that is opposite of its current one.

```py
# Swaps the case of each character in the string (uppercase becomes lowercase, and vice-versa).
df['FeedbackSwapcase'] = df['CleanedFeedback'].str.swapcase()
print("\nAfter df['CleanedFeedback'].str.swapcase():")
print(df[['CleanedFeedback', 'FeedbackSwapcase']].head())
print("-" * 30)
```
### 10. df['column_name'].str.casefold()
It is used to returns a case-folded copy of the string, which can be useful for caseless matching.

```py
# Converts strings to a case-folded form, which is more aggressive than .lower()
# for case-insensitive matching across different languages (e.g., 'ß' becomes 'ss').
df['FeedbackCasefold'] = df['CleanedFeedback'].str.casefold()
print("\nAfter df['CleanedFeedback'].str.casefold():")
print(df[['CleanedFeedback', 'FeedbackCasefold']].head())
print("-" * 30)
```
### Note
```py
# --- Important note: Handling NaN values ---
# All .str accessor methods (like .len(), .lower(), etc.) will return NaN for missing (NaN) values.
# If you want to perform operations and then fill NaNs or drop them, you'd do that separately.
# In our case conversions, we temporarily filled NaNs with '' to show the conversion;
# normally, you'd decide whether to drop NaNs or fill them appropriately before string ops.
```

### 11. Build the sample Datasets for String Check

```py
import pandas as pd
import numpy as np
import random
import string

# --- 1. Big Data Generation for String Checks ---
print("--- Generating Big Data for String Checks ---")

num_rows = 50000 # Let's create a large dataset with 50,000 rows
data = []

# Helper function to generate diverse string types
def generate_random_string(row_num):
    choice = random.randint(1, 10)
    
    if choice == 1: # Pure alphabetic
        return ''.join(random.choice(string.ascii_letters) for _ in range(random.randint(3, 10)))
    elif choice == 2: # Pure numeric (digits)
        return ''.join(random.choice(string.digits) for _ in range(random.randint(2, 7)))
    elif choice == 3: # Alphanumeric
        return ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(random.randint(5, 12)))
    elif choice == 4: # Spaces
        return ' ' * random.randint(1, 5)
    elif choice == 5: # Lowercase
        return ''.join(random.choice(string.ascii_lowercase) for _ in range(random.randint(4, 9)))
    elif choice == 6: # Uppercase
        return ''.join(random.choice(string.ascii_uppercase) for _ in range(random.randint(4, 9)))
    elif choice == 7: # Title case (simple simulation)
        word = ''.join(random.choice(string.ascii_lowercase) for _ in range(random.randint(3, 7)))
        return word.capitalize()
    elif choice == 8: # Mixed case
        return ''.join(random.choice(string.ascii_letters) for _ in range(random.randint(5, 10)))
    elif choice == 9: # Contains decimal/numeric but not pure digit/numeric
        return str(random.randint(1, 100)) + '.' + str(random.randint(0, 9))
    else: # Empty or Mixed with special chars
        if random.random() < 0.2:
            return '' # Empty string
        else:
            return ''.join(random.choice(string.ascii_letters + string.digits + ' !@#$') for _ in range(random.randint(5, 15)))

for i in range(num_rows):
    data.append({'ID': i + 1, 'text_data': generate_random_string(i)})

df = pd.DataFrame(data)
print(f"Generated DataFrame with {num_rows} rows.")
print("Sample of generated data:")
print(df.head(10))
print("-" * 50)
```
### 12. df['column_name'].str.isalnum()
Checks whether all characters are alphanumeric in the column.

```py
# .str.isalnum(): Check if all characters in the string are alphanumeric (letters or numbers)
# Returns True if string has at least one character and all characters are alphanumeric, False otherwise.
df['is_alphanumeric'] = df['text_data'].str.isalnum()
print("\n'isalnum()' Check (first 50 True/False values):")
print(df['is_alphanumeric'].value_counts()) # Count True/False occurrences
```
### 13. df['column_name'].str.isalpha()
Checks whether all characters are alphabetic in the column.

```py
# Returns True if string has at least one character and all characters are alphabetic, False otherwise.
df['is_alphabetic'] = df['text_data'].str.isalpha()
print("\n'isalpha()' Check (first 50 True/False values):")
print(df['is_alphabetic'].value_counts())
```
### 14. df['column_name'].str.isdecimal()
Checks whether all characters are decimal in the column.

```py
# Returns True if string has at least one character and all characters are decimal, False otherwise.
# Differs from isdigit()/isnumeric() by excluding some Unicode characters like ² or ½.
df['is_decimal'] = df['text_data'].str.isdecimal()
print("\n'isdecimal()' Check (first 50 True/False values):")
print(df['is_decimal'].value_counts())
```
### 15. df['column_name'].str.isdigit()
Checks whether all characters are digits in the column.

```py
# Returns True if string has at least one character and all characters are digits, False otherwise.
# Includes some Unicode digits (e.g., Arabic numerals) but not decimals like '¾'.
df['is_digit'] = df['text_data'].str.isdigit()
print("\n'isdigit()' Check (first 50 True/False values):")
print(df['is_digit'].value_counts())
```
### 16. df['column_name'].str.islower()
Checks whether all characters are lowercase in the column.

```py
# Returns True if string has at least one cased character and all cased characters are lowercase, False otherwise.
df['is_lowercase'] = df['text_data'].str.islower()
print("\n'islower()' Check (first 50 True/False values):")
print(df['is_lowercase'].value_counts())
```
### 17. df['column_name'].str.isnumeric()
Checks whether all characters are numeric in the column.

```py
# Returns True if string has at least one character and all characters are numeric, False otherwise.
# Broadest category for numbers; includes digits, decimals, and even Roman numerals or fractions like '½'.
df['is_numeric'] = df['text_data'].str.isnumeric()
print("\n'isnumeric()' Check (first 50 True/False values):")
print(df['is_numeric'].value_counts())
```
### 18. df['column_name'].str.isspace()
Checks whether all characters are whitespace in the column.

```py
# Returns True if string has at least one character and all characters are whitespace, False otherwise.
df['is_whitespace'] = df['text_data'].str.isspace()
print("\n'is_whitespace()' Check (first 50 True/False values):")
print(df['is_whitespace'].value_counts())
```
### 19. df['column_name'].str.istitle()
Checks whether all characters are titlecase in the column.

```py
# Returns True if string has at least one cased character and is titlecased (first letter of each word capitalized, rest lowercase), False otherwise.
df['is_titlecase'] = df['text_data'].str.istitle()
print("\n'is_titlecase()' Check (first 50 True/False values):")
print(df['is_titlecase'].value_counts())
```
### 20. df['column_name'].str.isupper()
Checks whether all characters are uppercase in the column.

```py
# Returns True if string has at least one cased character and all cased characters are uppercase, False otherwise.
df['is_uppercase'] = df['text_data'].str.isupper()
print("\n'is_uppercase()' Check (first 50 True/False values):")
print(df['is_uppercase'].value_counts())
```

### 21 . Build the sample Datasets for String slicing and replace

```py
# --- 1. Data Generation ---
print("\n1. Generating a large dataset (100,000 rows)...")

num_rows = 100_000

# Helper function to generate a random alphanumeric string
def generate_random_string(length, chars=string.ascii_uppercase + string.digits):
    return ''.join(random.choice(chars) for _ in range(length))

# Generate structured product codes: MANUFACTURER-PRODUCTID-LOCATION-SIZE
# Example: "ABC-12345-KOL-XL"
manufacturer_codes = [generate_random_string(3, string.ascii_uppercase) for _ in range(num_rows)]
product_ids = [generate_random_string(5, string.digits) for _ in range(num_rows)]
location_codes = [random.choice(['KOL', 'DEL', 'MUM', 'BLR', 'CHE']) for _ in range(num_rows)]
size_codes = [random.choice(['XS', 'SM', 'MD', 'LG', 'XL', 'XX']) for _ in range(num_rows)]

df = pd.DataFrame({
    'manufacturer': manufacturer_codes,
    'product_id': product_ids,
    'location': location_codes,
    'size': size_codes
})

# Combine them into a single 'product_code' string
df['product_code'] = df_big['manufacturer'] + '-' + \
                         df_big['product_id'] + '-' + \
                         df_big['location'] + '-' + \
                         df_big['size']

print(f"Generated DataFrame with {len(df)} rows. Head:")
print(df.head())
print(f"\nExample 'product_code': {df['product_code'].iloc[0]}")
print("-" * 50)
```

### 22. df['column_name'].str.slice()
It is a way of selecting a subset of characters from a string column.

```py
# ---  df['column_name'].str.slice() ---
print("\n2. Demonstrating .str.slice()...")

# Accessing specific parts of the product_code string column

# Example 1: Extract Manufacturer Code (first 3 characters, index 0 to 2)
df_big['extracted_manufacturer'] = df['product_code'].str.slice(0, 3)
print("\nAfter extracting manufacturer (first 5 rows):")
print(df[['product_code', 'extracted_manufacturer']].head())

# Example 2: Extract Product ID (5 digits after the first dash, index 4 to 8)
df['extracted_product_id'] = df['product_code'].str.slice(4, 9) # slice(start, stop) - stop is exclusive
print("\nAfter extracting product ID (first 5 rows):")
print(df[['product_code', 'extracted_product_id']].head())

# Example 3: Extract Location Code (3 characters after the second dash, index 10 to 12)
df['extracted_location'] = df['product_code'].str.slice(10, 13)
print("\nAfter extracting location (first 5 rows):")
print(df[['product_code', 'extracted_location']].head())

# Example 4: Extract Size Code (last 2 characters using negative indexing)
df['extracted_size'] = df['product_code'].str.slice(-2) # slice(-2) means from 2nd to last char to end
print("\nAfter extracting size (first 5 rows):")
print(df[['product_code', 'extracted_size']].head())

# Example 5: Extracting with a step (e.g., every second character of the product ID)
# Product ID is typically from index 4 to 8. So, slice(4, 9, 2)
df['product_id_every_second_char'] = df['product_code'].str.slice(4, 9, 2)
print("\nAfter extracting product ID every second char (first 5 rows):")
print(df[['product_code', 'product_id_every_second_char']].head())
print("-" * 50)
```

### 23. df['column_name'].str.slice_replace()
It enables us to replace a positional slice of a string with another value.

```py
# --- df['column_name'].str.slice_replace() ---
print("\n3. Demonstrating .str.slice_replace()...")

# Example 1: Anonymize the Product ID part (index 4 to 8) with "*****"
df['anonymized_product_code'] = df['product_code'].str.slice_replace(4, 9, '*****')
print("\nAfter anonymizing product ID (first 5 rows):")
print(df[['product_code', 'anonymized_product_code']].head())

# Example 2: Change Location Code to a generic 'GLOBAL' (index 10 to 12)
df['global_product_code'] = df['product_code'].str.slice_replace(10, 13, 'GLOBAL')
print("\nAfter changing location to 'GLOBAL' (first 5 rows):")
print(df[['product_code', 'global_product_code']].head())

# Example 3: Replace the entire string with a fixed value
df['all_replaced_code'] = df['product_code'].str.slice_replace(0, None, 'REPLACED_ENTIRELY') # None means till end
print("\nAfter replacing the entire string (first 5 rows):")
print(df[['product_code', 'all_replaced_code']].head())
```

### 24 . Build the sample Datasets for String split

```py
import pandas as pd
import numpy as np
import re # For regex splitting

print("--- Demonstrating df['column_name'].str.split() with  Data ---")

# ---  Data Generation (1 Million Rows) ---
print("\nGenerating a synthetic DataFrame with 1,000,000 rows...")

num_rows = 1_000_000

# Data for splitting with '-'
product_chars = np.random.choice(list('ABCDEFGHIJKLMNOPQRSTUVWXYZ'), size=num_rows)
product_nums = np.random.randint(1000, 99999, size=num_rows)
product_data = [f"PROD-{char}-{num}" for char, num in zip(product_chars, product_nums)]

# Data for regex splitting
user_ids = np.random.randint(10000, 99999, size=num_rows)
event_codes = np.random.choice(list('XYZ'), size=num_rows)
log_entries = [f"user{uid}action_TYPE{code}" for uid, code in zip(user_ids, event_codes)]

# Data for lambda function based split (e.g., getting specific parts after splitting)
sensor_ids = np.random.randint(100, 999, size=num_rows)
status_types = np.random.choice(['ACTIVE', 'INACTIVE', 'ERROR'], size=num_rows)
reading_values = np.round(np.random.rand(num_rows) * 100, 2)
complex_records = [f"sensor={sid};status={status};value={val}" for sid, status, val in zip(sensor_ids, status_types, reading_values)]


df = pd.DataFrame({
    'product_id_str': product_data,
    'event_log_str': log_entries,
    'sensor_record_str': complex_records
})

print(f"DataFrame generated with {len(df)} rows. Head:")
print(df.head())
print(f"\nDataFrame Info:")
df.info()
print("-" * 50)
```
### 25. df['column_name'].str.split()
It splits a string column into multiple columns based on a separator.

```py

# --- 1. Splitting values with '-' as separator (aka delimiter) ---
print("\n1. Splitting 'product_id_str' by '-' as separator:")
# This creates a Series where each element is a list of strings
df['product_id_parts'] = df['product_id_str'].str.split('-')

print("Resulting 'product_id_parts' column (first 5 rows):")
print(df[['product_id_str', 'product_id_parts']].head())
print("-" * 50)

# --- 2. Splitting and expand values ---

print("\n2. Splitting 'product_id_str' by '-' and expanding into new columns:")
# The `expand=True` argument turns the list of split strings into separate columns
product_expanded_df = df['product_id_str'].str.split('-', expand=True)

# Rename columns for clarity (optional, but good practice)
product_expanded_df.columns = ['prefix', 'product_char', 'product_num']

# You can then concatenate these new columns back to the original DataFrame if needed
df = pd.concat([df, product_expanded_df], axis=1)

print("Resulting DataFrame with expanded split columns (first 5 rows):")
print(df.head())
print("-" * 50)

# --- 3. Split by regex pattern ---

print("\n3. Splitting 'event_log_str' by a regex pattern (digits or 'action_'):")
# The pattern r'\d+|action_' means:
# \d+ : one or more digits
# |   : OR
# action_ : the literal string 'action_'
# Remove expand=True to assign the result as a list to a single column
df['event_log_parts'] = df['event_log_str'].str.split(r'\d+|action_')

print("Resulting 'event_log_parts' column (first 5 rows):")
print(df[['event_log_str', 'event_log_parts']].head())
print("\nNote: The first element might be empty string if the pattern matches at the start.")
print("-" * 50)


# --- 4. Lambda function based manipulation after split ---
print("\n4. Using a lambda function after splitting 'sensor_record_str' to extract specific parts:")
# Scenario: We want to extract only the sensor ID and status, ignoring the value part.
# First, split by ';' to get individual key=value pairs.
# Then, use a lambda function on each list to process its elements.

df['extracted_info'] = df['sensor_record_str'].str.split(';').apply(
    lambda x: {part.split('=')[0]: part.split('=')[1] for part in x if '=' in part}
)

# If you only want the 'status' for instance, after the split
df['sensor_status'] = df['sensor_record_str'].str.split(';').apply(
    lambda parts: next((val.split('=')[1] for val in parts if val.startswith('status=')), None)
)


print("Original 'sensor_record_str' and 'extracted_info' (first 5 rows):")
print(df[['sensor_record_str', 'extracted_info', 'sensor_status']].head())
print("-" * 50)

print("\nAll split operations completed on the large DataFrame.")
df.info() # Check memory usage after adding new columns

```

### 26 . Build the sample Datasets for String partition

```py
import pandas as pd
import numpy as np
import random
import string

print("--- Demonstrating df['column_name'].str.partition() ---")

# --- Step 1: Big Data Generation ---
# Let's create 100,000 synthetic email addresses for a 'big' dataset
num_records = 100_000

# Helper function to generate a random string
def generate_random_string(length=8):
    characters = string.ascii_lowercase + string.digits
    return ''.join(random.choice(characters) for i in range(length))

domains = ['example.com', 'mail.org', 'service.net', 'company.co.in', 'email.xyz']

email_data = []
for i in range(num_records):
    username = generate_random_string(random.randint(5, 12))
    domain = random.choice(domains)
    email = f"{username}@{domain}"
    email_data.append({'id': i + 1, 'email_address': email})

# Create a DataFrame
df = pd.DataFrame(email_data)

print(f"Generated a DataFrame with {len(df)} rows.")
print("\nFirst 5 rows of the original DataFrame:")
print(df.head())
print("-" * 50)
```

### 27. df['column_name'].str.partition()
It splits the string at the first occurrence of the separator.

```py
# ---  Applying .str.partition() ---

# We want to split the 'email_address' column by the '@' symbol.
# .str.partition('@') will return a DataFrame with three columns:
# 0: The part before the first occurrence of '@' (username)
# 1: The separator itself ('@')
# 2: The part after the first occurrence of '@' (domain)

print("Applying df['email_address'].str.partition('@')...")
email_parts = df['email_address'].str.partition('@')

print("\nFirst 5 rows of the DataFrame returned by .str.partition('@'):")
print(email_parts.head())
print("-" * 50)

# Often, you'll want to assign these parts to new columns in your original DataFrame
df[['username', 'separator', 'domain']] = email_parts

print("\nFirst 5 rows of the original DataFrame with new 'username', 'separator', and 'domain' columns:")
print(df.head())
print("-" * 50)

# --- Detailed Explanation ---
print("\n--- Detailed Explanation of df['column_name'].str.partition() ---")
print("`df['column_name'].str.partition(sep)` is a powerful Pandas string method used to split each string in a Series (column) into exactly three parts based on the *first occurrence* of a specified separator.")
print("\nInput:")
print(f"  - `df['column_name']`: This refers to a Pandas Series (a single column from your DataFrame) that contains string data.")
print(f"  - `sep`: This is the separator string. In our example, it's '@'.")

print("\nOutput:")
print("  - It returns a new DataFrame (or Series of tuples if only one column is processed) with three columns for each row:")
print("    1.  **The part before the separator:** If the separator is not found, this will be the entire original string.")
print("    2.  **The separator itself:** If the separator is not found, this will be an empty string.")
print("    3.  **The part after the separator:** If the separator is not found, this will also be an empty string.")

print("\nIn our example:")
print(f"  - For 'john.doe@{domains[0]}', it splits into: ('john.doe', '@', '{domains[0]}')")
print(f"  - This allowed us to easily extract the 'username' (part before '@'), confirm the 'separator' (which is always '@' in this case), and get the 'domain' (part after '@') for {num_records} email addresses efficiently.")
print("  - We then assigned these three resulting columns back to our original DataFrame using `df[['username', 'separator', 'domain']] = email_parts`.")

print("\nThis method is particularly useful when you expect a clear separator and need all three components, unlike `str.split()` which can return a variable number of parts and doesn't retain the separator itself.")
```


