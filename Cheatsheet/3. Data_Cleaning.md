<div align="left">
  <h1> 3. Pandas Cheatsheet - Data Cleaning

  ## Data Cleaning

### 1. Build in Datasets

```shell
tips
iris
penguins
flights
diamonds
titanic
exercise
mpg
planets
anagrams
anscombe
attention
brain_networks
car_crashes
dots
dowjones
fmri
geyser
glue
healthexp
seaice
taxis
```
### 2. Load the dataset

```py
import seaborn as sns

# Load the tips dataset
tips = sns.load_dataset('tips')
```

### 3. df.columns = ['a','b','c']
Renames all columns by assigning a new list of column names.

```py
import seaborn as sns
import pandas as pd # Import pandas as it's needed for DataFrame operations

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Rename columns
titanic.columns = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o']
# Note: The Titanic dataset has 15 columns, so you need to provide 15 new column names.
# I've expanded it to match the number of columns in the Titanic dataset.

# Optional: Print the first few rows with new column names to verify
print(titanic.head())
```
### 4. pd.isnull(obj)
Checks for null (NaN, None, NaT) values in a DataFrame or Series, returning a Boolean array/DataFrame.

```py
import seaborn as sns
import pandas as pd

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Check for null values in the entire DataFrame using pd.isnull()
# This returns a boolean DataFrame of the same shape, where True indicates a NaN value.
null_values_df = pd.isnull(titanic)

# Check for null values in a specific Series (e.g., 'age' column) using pd.isnull()
# This returns a boolean Series for that column.
null_values_age_series = pd.isnull(titanic['age'])

# You can print these boolean results to see where the NaNs are
# For brevity, we'll print only the head of the boolean DataFrame and Series
print("Boolean DataFrame indicating null values (first 5 rows):\n", null_values_df.head())
print("\nBoolean Series indicating null values in 'age' column (first 5 rows):\n", null_values_age_series.head())

# Commonly, pd.isnull() is chained with .sum() to count nulls per column:
# print("\nTotal null values per column (using .isnull().sum()):\n", titanic.isnull().sum())
```

### 5. pd.notnull(obj)
The inverse of pd.isnull(), checking for non-null values.

```py
import seaborn as sns
import pandas as pd # Import pandas as it's needed for pd.notnull

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Command: pd.notnull(obj)
# Description: Returns a boolean Series or DataFrame indicating where the data is NOT null (i.e., not NaN, None, or NaT).

# Example: Check for non-null values in the 'age' column
# The 'age' column is known to have missing values in the Titanic dataset.
non_null_age = pd.notnull(titanic['age'])

# Print the head of the boolean Series to demonstrate
print("Boolean Series indicating non-null values in 'age' column (first 10 rows):\n", non_null_age.head(10))

# You can also use it to count non-null values
print(f"\nTotal non-null age values: {non_null_age.sum()}")

# Or to filter the DataFrame to only include rows where 'age' is not null
non_null_age_df = titanic[pd.notnull(titanic['age'])]
print(f"\nDataFrame with non-null 'age' values (first 5 rows):\n", non_null_age_df.head())
```
### 6. df.dropna()
It drops all the rows that contain the null values.

```py
import seaborn as sns
import matplotlib.pyplot as plt # Not strictly needed for dropna, but kept for consistency with your format

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Apply df.dropna()
# This will remove all rows that contain at least one NaN (missing) value.
titanic_cleaned = titanic.dropna()

# You can print the shape or info to see the effect of dropna()
# print("Original DataFrame shape:", titanic.shape)
# print("Cleaned DataFrame shape (after dropna):", titanic_cleaned.shape)
# print("\nInfo of cleaned DataFrame:\n", titanic_cleaned.info())
```
### 7. df.dropna(axis= 1)
It drops all the columns that contain null values.

```py
import seaborn as sns
import pandas as pd # Import pandas to work with DataFrames

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Drop columns with any missing values
titanic_cleaned_cols = titanic.dropna(axis=1)

# Print the shape of the original and cleaned DataFrames to see the effect
print("Original Titanic DataFrame shape:", titanic.shape)
print("Titanic DataFrame shape after dropping columns with NaNs:", titanic_cleaned_cols.shape)

# Optionally, print the first few rows of the cleaned DataFrame to inspect
print("\nFirst 5 rows of DataFrame after dropping columns with NaNs:")
print(titanic_cleaned_cols.head())
```
### 8. df.dropna(how='all')
Drops rows where all values are null. (Often axis=0 is implied).

```py
import seaborn as sns
import pandas as pd # pandas is implicitly used by seaborn's load_dataset, good to include

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Original DataFrame info for context
print("--- Original DataFrame Info ---")
titanic.info()
print("\nOriginal DataFrame (first 5 rows):\n", titanic.head())
print("\nShape before dropna:", titanic.shape)
print("Number of NaNs before dropna (per column):\n", titanic.isnull().sum())

# Apply the dropna(how='all') command
# This drops rows where ALL values are NaN.
# In the Titanic dataset, it's unlikely to drop any rows unless a row is entirely empty.
titanic_cleaned = titanic.dropna(how='all')

# Display information after the operation
print("\n--- DataFrame Info After dropna(how='all') ---")
titanic_cleaned.info()
print("\nDataFrame after dropna(how='all') (first 5 rows):\n", titanic_cleaned.head())
print("\nShape after dropna:", titanic_cleaned.shape)
print("Number of NaNs after dropna (per column):\n", titanic_cleaned.isnull().sum())
```
### 9. df.dropna(axis=1, how='all')
Drops columns where all values are null.

```py
import seaborn as sns
import pandas as pd # pandas is implicitly used by seaborn's load_dataset

# Load the Titanic dataset
titanic_df = sns.load_dataset('titanic')

# Apply the dropna command to remove columns where all values are NaN
titanic_df_cleaned = titanic_df.dropna(axis=1, how='all')

# You can print the shape before and after to see the effect
print("Original DataFrame shape:", titanic_df.shape)
print("DataFrame shape after dropping all-NaN columns:", titanic_df_cleaned.shape)

# Optionally, display the first few rows of the cleaned DataFrame
print("\nFirst 5 rows of DataFrame after dropping all-NaN columns:")
print(titanic_df_cleaned.head())
```

### 10. df.dropna(subset=['col1', 'col2'])
Drops rows that have null values only in the specified subset of columns.

```py
import seaborn as sns
import pandas as pd

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Original number of rows
print(f"Original number of rows: {len(titanic)}")

# Number of rows before dropping NaNs in specified columns
print(f"Number of rows before dropping NaNs in 'age' or 'embarked': {len(titanic)}")

# Drop rows where 'age' or 'embarked' columns have NaN values
# 'inplace=True' modifies the DataFrame directly without returning a new one
titanic.dropna(subset=['age', 'embarked'], inplace=True)

# Number of rows after dropping NaNs
print(f"Number of rows after dropping NaNs in 'age' or 'embarked': {len(titanic)}")

# Display the first few rows of the modified DataFrame to show the effect
print("\nDataFrame after dropping NaNs in 'age' or 'embarked' (first 5 rows):\n", titanic.head())
```
### 11. df.dropna(thresh=n)
Drops rows where all values are null. (Often axis=0 is implied).

```py
import seaborn as sns
import pandas as pd # Import pandas to work with DataFrames

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Original shape of the DataFrame
print("Original DataFrame shape:", titanic.shape)

# Drop rows that have less than 'n' non-NaN values
# Let's choose n = 10, meaning a row must have at least 10 non-NaN values to be kept.
n = 10
df_dropped_thresh = titanic.dropna(thresh=n)

# Print the shape after dropping rows
print(f"DataFrame shape after dropping rows with less than {n} non-NaN values:", df_dropped_thresh.shape)

# Display the first few rows of the DataFrame after the operation (optional)
print("\nFirst 5 rows after dropna(thresh=n):\n", df_dropped_thresh.head())
```

### 12. df.dropna(axis=1,thresh=n)
Drops rows that have fewer than n non-null values.

```py
import seaborn as sns
import pandas as pd # Import pandas for DataFrame operations

# Load the titanic dataset
df = sns.load_dataset('titanic')

# --- Implementation of df.dropna(axis=1, thresh=n) ---

# Get the original shape and columns
print("Original DataFrame shape:", df.shape)
print("Original DataFrame columns:\n", df.columns.tolist())

# Set a threshold 'n'.
# 'n' represents the minimum number of non-NaN values required for a column to be kept.
# Columns with fewer than 'n' non-NaN values will be dropped.
# Let's choose a threshold that will likely drop columns with significant missing data,
# for example, 'deck' which has many NaNs.
n = len(df) - 200 # This will keep columns with at least (total rows - 200) non-NaN values

# Apply dropna with axis=1 (columns) and the specified threshold
df_cleaned = df.dropna(axis=1, thresh=n)

# Print the shape and columns after dropping
print("\nDataFrame shape after dropping columns with less than", n, "non-NaN values:", df_cleaned.shape)
print("Columns after dropping:\n", df_cleaned.columns.tolist())
```

### 13. df.fillna(x)
It replaces all null values with x.

```py
import pandas as pd
import seaborn as sns

# Load the Titanic dataset
df = sns.load_dataset('titanic')

# Display the number of missing values in each column before filling
print("Missing values before fillna:\n", df.isnull().sum())

# Choose a specific column that typically has missing values, e.g., 'age'
# We will fill missing values in the 'age' column with the specific number 0.
# You can replace '0' with any specific number you need.
specific_fill_number = 0
df['age'] = df['age'].fillna(specific_fill_number)

# Display the number of missing values in each column after filling
print("\nMissing values after fillna (in 'age' column with", specific_fill_number, "):\n", df.isnull().sum())

# Optional: Display a sample of the DataFrame to show the filled values
print("\nDataFrame head after filling 'age' NaNs with", specific_fill_number, ":")
print(df.head())
```

### 14. s.fillna(s.mean())
It replaces all the null values with the mean(the mean can be replaced with almost any function from the statistics module).

```py
import seaborn as sns
import pandas as pd # pandas is implicitly used by seaborn's load_dataset

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Select a Series with missing values (e.g., 'age' column)
s = titanic['age']

# Print the number of missing values before filling
print(f"Number of NaN values in 'age' before fillna: {s.isnull().sum()}")
print("Original 'age' Series (first 10 values):\n", s.head(10))

# Fill NaN values in the Series with its mean
s_filled = s.fillna(s.mean())

# Print the number of missing values after filling
print(f"\nNumber of NaN values in 'age' after fillna: {s_filled.isnull().sum()}")
print("Filled 'age' Series (first 10 values):\n", s_filled.head(10))
```

### 15. df.fillna({'col1': val1, 'col2': val2})
Replaces null values with different specified values per column.

```py
import seaborn as sns
import pandas as pd # Import pandas to work with DataFrames

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Before fillna, let's see current missing values (optional, for context)
print("Missing values before fillna:")
print(titanic.isnull().sum()[titanic.isnull().sum() > 0])

# Define the values to fill for specific columns
# 'Age': fill with the median age
# 'Embarked': fill with the most frequent embarkation port (mode)
# 'deck': fill with a placeholder string 'Unknown'
fill_values = {
    'Age': titanic['age'].median(),
    'embarked': titanic['embarked'].mode()[0], # .mode() returns a Series, take the first element
    'deck': 'Unknown'
}

# Add 'Unknown' to the categories of the 'deck' column before filling
# This prevents the TypeError when trying to insert a new category
if 'Unknown' not in titanic['deck'].cat.categories:
    titanic['deck'] = titanic['deck'].cat.add_categories('Unknown')


# Apply fillna to the DataFrame
titanic_filled = titanic.fillna(fill_values)

# After fillna, let's verify missing values (optional, for verification)
print("\nMissing values after fillna:")
print(titanic_filled.isnull().sum()[titanic_filled.isnull().sum() > 0])

# Display a sample of the filled DataFrame to show the effect (optional)
print("\nSample of DataFrame after fillna (showing affected columns):")
print(titanic_filled[['age', 'embarked', 'deck']].head())
print("\nSample of DataFrame tail (showing affected columns):")
print(titanic_filled[['age', 'embarked', 'deck']].tail())
```
### 16. df.fillna(method='ffill')
Replaces null values by propagating the last valid observation forward to next valid observation (forward fill).

```py
import seaborn as sns
import pandas as pd # pandas is implicitly used by seaborn, but good to import explicitly

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# --- Demonstrate df.fillna(method='ffill') ---
# Create a copy to show the effect without modifying the original loaded dataset
df_filled_ffill = titanic.copy()

# Introduce some NaNs deliberately for a clearer demonstration if needed,
# though 'Age' and 'Deck' often have them.
# For example, let's artificially set some 'Age' values to NaN
# df_filled_ffill.loc[df_filled_ffill.index % 10 == 0, 'age'] = pd.NA # Or np.nan

# Before applying ffill, let's see the initial NaN count for a relevant column
print("NaN count in 'age' column BEFORE ffill:", df_filled_ffill['age'].isnull().sum())
print("NaN count in 'deck' column BEFORE ffill:", df_filled_ffill['deck'].isnull().sum())

# Apply forward fill to the entire DataFrame
# This will fill NaN values by carrying the last valid observation forward.
# Note: For columns with NaNs at the very beginning, ffill won't fill them.
df_filled_ffill = df_filled_ffill.fillna(method='ffill')

# After applying ffill, let's see the NaN count again
print("\nNaN count in 'age' column AFTER ffill:", df_filled_ffill['age'].isnull().sum())
print("NaN count in 'deck' column AFTER ffill:", df_filled_ffill['deck'].isnull().sum())

# Display a sample of the DataFrame to show the effect,
# especially around where NaNs were expected or created.
print("\nSample of DataFrame after ffill (head):\n", df_filled_ffill.head(10))
print("\nSample of DataFrame after ffill (tail):\n", df_filled_ffill.tail(10))
```
### 17. df.fillna(method='bfill')
Replaces null values by propagating the next valid observation backward to previous valid observation (backward fill).

```py
import seaborn as sns
import pandas as pd # Import pandas to work with DataFrames

# Load the Titanic dataset
df = sns.load_dataset('titanic')

# --- Introduce some NaNs for demonstration if they aren't abundant enough ---
# For example, let's intentionally set some values to NaN in 'age' and 'fare'
# to clearly see bfill's effect, especially in rows where 'age' might be NaN
# but 'fare' has a value, or vice-versa.
df.loc[df.index % 5 == 0, 'age'] = pd.NA # Set age to NaN for every 5th row
df.loc[df.index % 7 == 0, 'fare'] = pd.NA # Set fare to NaN for every 7th row

print("Original DataFrame with introduced NaNs (first 10 rows):\n", df.head(10))
print("\nNaNs before bfill:\n", df[['age', 'fare']].isnull().sum())

# Apply backward fill to the entire DataFrame
# This will fill NaN values using the next valid observation in each column.
df_bfilled = df.fillna(method='bfill')

print("\nDataFrame AFTER bfill (first 10 rows):\n", df_bfilled.head(10))
print("\nNaNs after bfill:\n", df_bfilled[['age', 'fare']].isnull().sum())
```
### 18. df.fillna(value=df.mean())
Replaces null values in each column with that column's mean.

```py
import seaborn as sns
import pandas as pd # pandas is implicitly used by seaborn's load_dataset

# Load the Titanic dataset
df = sns.load_dataset('titanic')

# Display initial info to see NaN values (e.g., 'age', 'embark_town', 'deck')
print("--- DataFrame info before fillna ---")
df.info()

print("\n--- Head of DataFrame before fillna (showing NaNs) ---")
print(df.head())

# Apply fillna: Replace NaN values in numerical columns with the mean of their respective columns
# Note: df.mean() will calculate the mean only for numerical columns by default.
# Non-numerical columns (like 'sex', 'embarked', 'deck') will not be affected by this operation.
df_filled = df.fillna(value=df.mean(numeric_only=True))

print("\n--- DataFrame info after fillna ---")
# Check info again to see if NaN counts for numerical columns have changed
df_filled.info()

print("\n--- Head of DataFrame after fillna (showing filled values) ---")
print(df_filled.head())

# Optional: Verify a specific column (e.g., 'age') where NaNs were present
print("\n--- Sample of 'age' column after fillna ---")
print(df_filled['age'].sample(10)) # Sample to see if NaNs are replaced
```
### 19. s.astype(dtype)
Converts the data type of a Series s to the specified dtype (e.g., 'float', 'int', 'str', datetime).

```py
import seaborn as sns
import pandas as pd

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Select a Series (e.g., 'pclass' which might be an integer or categorical,
# or 'survived' which is usually an integer 0/1)
# and convert its data type using .astype(dtype)

# Example 1: Convert 'pclass' to 'category' type
# 'pclass' typically represents passenger class (1st, 2nd, 3rd)
# and is often better represented as a categorical variable than an integer.
titanic['pclass_categorical'] = titanic['pclass'].astype('category')
print("--- After converting 'pclass' to 'category' ---")
print(titanic[['pclass', 'pclass_categorical']].head())
print("\nOriginal 'pclass' dtype:", titanic['pclass'].dtype)
print("New 'pclass_categorical' dtype:", titanic['pclass_categorical'].dtype)

# Example 2: Convert 'survived' to 'bool' type
# 'survived' is 0 for not survived, 1 for survived. Converting to boolean can be more intuitive.
titanic['survived_boolean'] = titanic['survived'].astype(bool)
print("\n--- After converting 'survived' to 'bool' ---")
print(titanic[['survived', 'survived_boolean']].head())
print("\nOriginal 'survived' dtype:", titanic['survived'].dtype)
print("New 'survived_boolean' dtype:", titanic['survived_boolean'].dtype)
```
### 20. df['col'].astype(dtype)
Converts the data type of a specific column in a DataFrame.

```py
import seaborn as sns

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Original dtype of 'survived' column
print("Original dtype of 'survived' column:", titanic['survived'].dtype)

# Convert the 'survived' column to boolean type
titanic['survived'] = titanic['survived'].astype(bool)

# New dtype of 'survived' column
print("New dtype of 'survived' column:", titanic['survived'].dtype)

# Display the head of the DataFrame to show the change
print("\nDataFrame head after converting 'survived' to boolean:\n", titanic.head())
```
### 21. s.replace(old_value, new_value)
Replaces all occurrences of old_value with new_value across the entire DataFrame.

```py
import seaborn as sns
import pandas as pd # Import pandas as we'll be working with Series objects

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# --- Example of s.replace(old_value, new_value) ---
# We will replace values in the 'embark_town' Series (a column from the DataFrame).
# First, let's see the unique values before replacement.
print("Original 'embark_town' unique values:\n", titanic['embark_town'].unique())

# Replace 'Southampton' with 'Soton' for brevity
# Note: .copy() is used to avoid SettingWithCopyWarning if you intend to modify the original DataFrame later
#       without explicitly assigning back. For this example, it's good practice.
embark_town_modified = titanic['embark_town'].replace('Southampton', 'Soton')
```
### 22. s.replace([val1, val2], [new_val1, new_val2])
Replaces multiple old values with corresponding new values in a Series.

```py
import seaborn as sns
import pandas as pd

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Select a Series (column) to demonstrate the replace method.
# The 'Sex' column is suitable as it contains 'male' and 'female' values.
sex_series = titanic['sex']

print("Original 'sex' Series (first 5 rows):\n", sex_series.head())

# Use the replace method to change 'male' to 0 and 'female' to 1
# s.replace([old_values], [new_values])
sex_series_encoded = sex_series.replace(['male', 'female'], [0, 1])

print("\nModified 'sex' Series (first 5 rows) after replacing 'male' with 0 and 'female' with 1:\n", sex_series_encoded.head())
print("\nModified 'sex' Series (last 5 rows) for verification:\n", sex_series_encoded.tail())
```

### 23. df.replace(old_value, new_value)
Replaces all occurrences of old_value with new_value across the entire DataFrame.

```py
import seaborn as sns
import pandas as pd

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Select a Series (column) to demonstrate the replace method.
# The 'Sex' column is suitable as it contains 'male' and 'female' values.
sex_series = titanic['sex']

print("Original 'sex' Series (first 5 rows):\n", sex_series.head())

# Use the replace method to change 'male' to 0 and 'female' to 1
# s.replace([old_values], [new_values])
sex_series_encoded = sex_series.replace(['male', 'female'], [0, 1])

print("\nModified 'sex' Series (first 5 rows) after replacing 'male' with 0 and 'female' with 1:\n", sex_series_encoded.head())
print("\nModified 'sex' Series (last 5 rows) for verification:\n", sex_series_encoded.tail())
```
### 24. df.replace({'col_name': {old_val: new_val}})
Replaces values specifically within a designated column of a DataFrame.

```py
import seaborn as sns
import pandas as pd # pandas is implicitly needed for DataFrame operations

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Example of using df.replace({'col_name': {old_val: new_val}})
# Let's say we want to replace 'male' with 'M' and 'female' with 'F' in the 'sex' column
# And replace 'C' (Cherbourg) with 'Cherbourg', 'Q' (Queenstown) with 'Queenstown', 'S' (Southampton) with 'Southampton' in 'embark_town'

# Before replacement (optional, for comparison)
print("--- 'sex' column before replacement (first 5 rows) ---")
print(titanic['sex'].head())
print("\n--- 'embark_town' column before replacement (first 5 rows) ---")
print(titanic['embark_town'].head())


# Apply the replacement
# Using inplace=True modifies the DataFrame directly, or you can assign it back:
# titanic = titanic.replace({'sex': {'male': 'M', 'female': 'F'}})
titanic.replace({
    'sex': {'male': 'M', 'female': 'F'},
    'embark_town': {'Cherbourg': 'C', 'Queenstown': 'Q', 'Southampton': 'S'}
}, inplace=True) # Using inplace=True to modify the DataFrame directly


# After replacement (optional, for verification)
print("\n--- 'sex' column AFTER replacement (first 5 rows) ---")
print(titanic['sex'].head())
print("\n--- 'embark_town' column AFTER replacement (first 5 rows) ---")
print(titanic['embark_town'].head())

# To show unique values after replacement (for verification)
print("\n--- Unique values in 'sex' column after replacement ---")
print(titanic['sex'].unique())
print("\n--- Unique values in 'embark_town' column after replacement ---")
print(titanic['embark_town'].unique()) # Will show 'C', 'Q', 'S' and NaN
```
### 25. df.replace({'col1': {old_val1: new_val1}, 'col2': {old_val2: new_val2}})
Replaces values differently across multiple specific columns.

```py
import seaborn as sns
import matplotlib.pyplot as plt # Though not used for plotting here, keeping for format consistency

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Implement df.replace()
# Example: Replacing 'male' with 'M' and 'female' with 'F' in the 'sex' column
# and 'S' (Southampton) with 'C' (Cherbourg) in the 'embark_town' column
titanic.replace(
    {
        'sex': {'male': 'M', 'female': 'F'},
        'embark_town': {'Southampton': 'S', 'Cherbourg': 'C', 'Queenstown': 'Q'}
    },
    inplace=True # Use inplace=True to modify the DataFrame directly
)

# Optional: Print a sample of the modified DataFrame to verify the changes
print(titanic[['sex', 'embark_town']].head())
print(titanic['sex'].value_counts())
print(titanic['embark_town'].value_counts())

# No plotting is required here, so plt.show() is not used.
```
### 26. df.rename(columns=lambda x: x + '_new')
Renames columns using a function (e.g., appending _new to each name).

```py
import seaborn as sns
import pandas as pd # pandas is needed to work with DataFrames

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Rename columns by appending '_new' to each column name
titanic_renamed = titanic.rename(columns=lambda x: x + '_new')

# Display the first few rows of the DataFrame with renamed columns
print(titanic_renamed.head())
```
### 27. df.rename(columns={'old_name': 'new_name'})
Renames specific columns using a dictionary mapping.

```py
import seaborn as sns
import matplotlib.pyplot as plt # Not directly used for rename, but kept for format consistency

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Rename a column (e.g., 'pclass' to 'passenger_class')
titanic.rename(columns={'pclass': 'passenger_class', 'sibsp': 'siblings_spouses_aboard', 'parch': 'parents_children_aboard'}, inplace=True)

# Display the first few rows with the renamed columns to verify
print(titanic.head())
```
### 28. df.set_index('column_one')
Sets a specified column as the new DataFrame index.

```py
import seaborn as sns
import matplotlib.pyplot as plt # Although not directly used for plotting here, it's in the provided template

# Load the Titanic dataset
df = sns.load_dataset('titanic')

# Set 'Fare' as the index of the DataFrame
# Note: Setting a non-unique column like 'fare' as index will result in duplicate index entries.
# For demonstration purposes, we're following the syntax requested.
df_indexed = df.set_index('fare')

# You can print a portion of the new DataFrame to see the effect
print("DataFrame after setting 'fare' as index (first 5 rows):\n", df_indexed.head())
```
### 29. df.reset_index()
Resets the index to the default integer index, optionally moving the current index to a column.

```py
import seaborn as sns
import pandas as pd # pandas is implicitly used by seaborn's load_dataset

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# --- Code Block for df.reset_index() ---

# Scenario: Calculate the average age and fare for each Pclass and Sex,
# which naturally creates a MultiIndex. Then, reset this index.
df_grouped = titanic.groupby(['pclass', 'sex'])[['age', 'fare']].mean()

print("DataFrame after groupby (MultiIndex):\n", df_grouped.head())
print("\nIndex type before reset_index():", type(df_grouped.index))


# Apply reset_index() to convert the index levels into regular columns
df_reset = df_grouped.reset_index()

print("\nDataFrame after reset_index():\n", df_reset.head())
print("\nIndex type after reset_index():", type(df_reset.index))
print("Columns after reset_index():", df_reset.columns.tolist())

```
### 30. df.rename(index=lambda x: x + 1)
Renames index labels using a function.

```py
import seaborn as sns
import pandas as pd # pandas is implicitly needed for DataFrame operations

# Load the titanic dataset
df = sns.load_dataset('titanic')

# Rename the index by adding 1 to each index value
df.rename(index=lambda x: x + 1, inplace=True)

# Display the first few rows with the modified index to confirm
print(df.head())
```
### 31. df.rename(index={old_label: new_label})
Renames specific index labels using a dictionary mapping.

```py
import seaborn as sns
import pandas as pd # pandas is implicitly needed for DataFrame operations


# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Display the original index (first few rows) to see labels before renaming
print("Original DataFrame head:\n", titanic.head())
print("\nOriginal Index type:", type(titanic.index))

# Example: Rename a specific index label.
# This is most useful if your index has meaningful string labels,
# or if you want to rename specific row numbers if the index is integer-based.
# For demonstration, let's assume we want to rename the first few default integer index labels.
# In a real scenario, you'd usually rename based on meaningful labels if the index isn't just range(n).

# Let's rename index label 0 to 'First_Passenger' and 1 to 'Second_Passenger'
titanic.rename(index={0: 'First_Passenger', 1: 'Second_Passenger'}, inplace=True)

# Display the DataFrame head after renaming to see the effect
print("\nDataFrame head after renaming index labels 0 and 1:\n", titanic.head())
```
### 32. df.drop_duplicates()
Removes duplicate rows based on all columns.

```py
import seaborn as sns
import pandas as pd # pandas is implicitly needed for DataFrame operations

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Apply df.drop_duplicates()
# This operation will remove duplicate rows from the DataFrame.
# By default, it considers all columns to identify duplicates and keeps the first occurrence.
titanic_deduplicated = titanic.drop_duplicates()

# Optional: Print shape before and after to show the effect
print("Original DataFrame shape:", titanic.shape)
print("Deduplicated DataFrame shape:", titanic_deduplicated.shape)

# Optional: Display the first few rows of the deduplicated DataFrame
print("\nDeduplicated DataFrame (first 5 rows):\n", titanic_deduplicated.head())
```
### 33. df.drop_duplicates(subset=['col1'])
Removes duplicate rows based only on specified columns.

```py
import pandas as pd
import seaborn as sns

# Load the Titanic dataset
titanic_df = sns.load_dataset('titanic')

# Print the shape before dropping duplicates to see the original number of rows
print("Shape of DataFrame before dropping duplicates:", titanic_df.shape)

# Drop duplicate rows based on the 'sex' column
# This means if multiple rows have the same value in the 'sex' column,
# all but the first occurrence will be removed.
# Note: This will result in only 2 rows (one for 'male', one for 'female')
# since 'sex' is a binary column. This is a demonstration of the function,
# not necessarily a typical data cleaning step for this specific column.
df_no_sex_duplicates = titanic_df.drop_duplicates(subset=['sex'])

# Print the shape of the DataFrame after dropping duplicates
print("Shape of DataFrame after dropping duplicates based on 'sex':", df_no_sex_duplicates.shape)

# Display the resulting DataFrame to show the effect
print("\nDataFrame after dropping duplicates based on 'sex':\n", df_no_sex_duplicates)
```
### 34. df.drop_duplicates(keep='last')
Removes duplicates, keeping the last occurrence. (Default is first).

```py
import seaborn as sns
import pandas as pd # pandas is implicitly used by seaborn's load_dataset

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Apply df.drop_duplicates(keep='last')
# This operation will remove duplicate rows, keeping only the last occurrence of each duplicate set.
# Note: In the Titanic dataset, it's highly unlikely that there will be exact duplicate rows
# across all columns. However, this demonstrates the command's syntax and purpose.
# If you wanted to drop duplicates based on a subset of columns (e.g., 'pclass', 'sex'),
# you would specify that: titanic.drop_duplicates(subset=['pclass', 'sex'], keep='last')
titanic_deduplicated = titanic.drop_duplicates(keep='last')

# You can optionally print the shapes to see the effect (if any)
# print("Original DataFrame shape:", titanic.shape)
# print("Deduplicated DataFrame shape:", titanic_deduplicated.shape)

# No plotting required as per the instruction
```
### 35. df.duplicated()
Returns a Boolean Series indicating duplicate rows.

```py
import seaborn as sns
import pandas as pd # pandas is implicitly used by seaborn's load_dataset

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Check for duplicate rows in the DataFrame
duplicates = titanic.duplicated()

# Optional: Print the Series indicating duplicates (True for duplicate rows)
print(duplicates)

```
### 36. df.duplicated(subset=['col1'])
Returns a Boolean Series indicating duplicate rows based on specified columns.

```py
import seaborn as sns
import pandas as pd # Import pandas as it's needed for DataFrame operations

# Load the Titanic dataset
titanic_df = sns.load_dataset('titanic')

# Check for duplicate rows based on a subset of columns, for example, 'age' and 'sex'
# This will return a boolean Series indicating which rows are duplicates (True)
# The first occurrence of a duplicate set is marked as False by default.
duplicated_rows_subset = titanic_df.duplicated(subset=['age', 'sex'])

# To see the actual duplicate rows, you can filter the DataFrame
# duplicated(keep=False) marks all occurrences of duplicates as True
all_duplicate_occurrences = titanic_df[titanic_df.duplicated(subset=['age', 'sex'], keep=False)]

print("Boolean Series indicating duplicates based on 'age' and 'sex' (first occurrence is False):\n", duplicated_rows_subset.head())
print("\nNumber of duplicate rows found (excluding first occurrence):", duplicated_rows_subset.sum())

print("\nAll occurrences of duplicate rows based on 'age' and 'sex' (first 5):\n", all_duplicate_occurrences.head())
print("\nTotal number of rows that are duplicates (including first occurrences):", len(all_duplicate_occurrences))
```
### 37. df.astype({'col1': 'int', 'col2': 'float'})
Converts data types for multiple specific columns at once.

```py
import seaborn as sns
import matplotlib.pyplot as plt # Not directly used for astype, but included as per format

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Example of using .astype() to change column data types
# For illustration, let's assume we want to convert 'pclass' to float
# and 'age' (which might have NaNs and thus be float) to nullable integer type
# if we were certain of no decimals and wanted integer representation,
# or to a different numeric type for demonstration.
# Note: 'age' has NaN values, so converting it directly to 'int' would raise an error.
# We'll use 'Int64' (nullable integer type) for 'age' to handle NaNs,
# and convert 'pclass' to 'float'.

# Select relevant columns and apply astype
titanic_converted = titanic.astype({
    'pclass': 'float',  # Passenger Class (originally int) converted to float
    'age': 'Int64'      # Age (originally float due to NaNs) converted to nullable integer
                        # Using 'Int64' (capital I) allows for NaN values in integer columns.
})

# Display the data types before and after conversion to verify
print("Original DataFrame dtypes:\n", titanic.dtypes)
print("\nDataFrame dtypes after .astype():\n", titanic_converted.dtypes)

# You can also inspect a subset of the DataFrame to see the effect
print("\nFirst 5 rows of 'pclass' and 'age' after conversion:\n", titanic_converted[['pclass', 'age']].head())
```
### 38. pd.to_numeric(s, errors='coerce')
Converts Series s to numeric, converting unparseable values to NaN.

```py
import pandas as pd
import numpy as np # Used for creating some non-numeric data for demonstration

# Create a sample DataFrame with a column that might contain non-numeric data
data = {
    'ID': [1, 2, 3, 4, 5],
    'Value': ['10', '20', '30a', '40', 'abc']
}
df = pd.DataFrame(data)

print("Original DataFrame:\n", df)
print("\nOriginal 'Value' column dtype:", df['Value'].dtype)

# Apply pd.to_numeric with errors='coerce' to the 'Value' column
# This attempts to convert the column to a numeric type.
# If it encounters a value that cannot be converted (like '30a' or 'abc'),
# it will replace that value with NaN (Not a Number) instead of raising an error.
df['Value_Numeric'] = pd.to_numeric(df['Value'], errors='coerce')

print("\nDataFrame after pd.to_numeric with errors='coerce':\n", df)
print("\nNew 'Value_Numeric' column dtype:", df['Value_Numeric'].dtype)
```
### 39. pd.to_datetime(s, errors='coerce')
Converts Series s to datetime objects, converting unparseable values to NaT.

```py
import pandas as pd

# --- Demonstrating pd.to_datetime(s, errors='coerce') ---
# The Titanic dataset doesn't have a direct 'date' column that would typically
# require 'errors='coerce''. So, we'll create a hypothetical Series
# with some date-like strings, including some invalid ones, to showcase the function.

# Create a sample Series with date strings, some of which are invalid
date_strings = pd.Series([
    '2023-01-01',
    '2023-02-29',  # Invalid date for non-leap year, but valid in 2023 (as a string)
    '2023-13-01',  # Invalid month
    'not-a-date',  # Completely invalid
    '2024-02-29',  # Valid for a leap year
    '15/03/2023'
])

print("Original Series of date strings:\n", date_strings)

# Convert the Series to datetime objects, coercing errors to NaT (Not a Time)
# 'errors='coerce'' will turn any parsing failures into NaT.
datetime_series_coerced = pd.to_datetime(date_strings, errors='coerce')

print("\nConverted Series with 'errors='coerce'':\n", datetime_series_coerced)
print("\nData type of the converted Series:", datetime_series_coerced.dtype)
```
### 40. pd.to_timedelta(s, errors='coerce')
Converts Series s to timedelta objects.

```py
import pandas as pd

# Create a sample Pandas Series 's' with values that can be converted to timedelta.
# These could represent durations, time differences, etc.
s = pd.Series([
    '1 day',
    '2 hours',
    '30 minutes',
    'not a time', # This value will cause an error
    '5 seconds'
])

# Convert the Series to timedelta objects.
# 'errors='coerce'' will turn any unparseable values into NaT (Not a Time).
timedelta_series = pd.to_timedelta(s, errors='coerce')

# Print the original and converted Series to show the effect
print("Original Series:\n", s)
print("\nConverted Timedelta Series:\n", timedelta_series)

# You can also see the dtype of the resulting Series
print("\nConverted Series dtype:", timedelta_series.dtype)

```
### 41. df.loc[df['col'].isin(['val1', 'val2'])]
Filters rows where a column's value is in a given list.

```py
import seaborn as sns
import pandas as pd # Import pandas as it's used for DataFrame operations

# Load the titanic dataset
titanic = sns.load_dataset('titanic')

# Example: Filter the DataFrame to include only rows where 'Sex' is 'male' or 'female'
# (though 'Sex' only contains these values, this demonstrates the usage)
# Or, a more useful example: Filter for specific Embarked locations 'S' (Southampton) or 'C' (Cherbourg)
filtered_titanic_embarked = titanic.loc[titanic['embarked'].isin(['S', 'C'])]

# Print the head of the filtered DataFrame to show the result
print("Filtered Titanic DataFrame (Embarked from 'S' or 'C'):")
print(filtered_titanic_embarked.head())

# Another example: Filter for specific passenger classes (1st or 2nd class)
filtered_titanic_class = titanic.loc[titanic['pclass'].isin([1, 2])]

# Print the head of this filtered DataFrame
print("\nFiltered Titanic DataFrame (Passenger Class 1 or 2):")
print(filtered_titanic_class.head())
```
### 42. df.loc[~df['col'].isin(['val1', 'val2'])]
Filters rows where a column's value is NOT in a given list.

```py
import seaborn as sns
import pandas as pd

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Example: Filter out rows where 'sex' is 'male' or 'female'
# This will effectively leave an empty DataFrame or rows where 'sex' is NaN if any existed
# A more practical example would be filtering out specific 'class' values.
# Let's refine the example to be more illustrative:
# Filter out rows where 'class' is 'First' or 'Third'

# Command to filter rows where the 'class' column is NOT 'First' and NOT 'Third'
# This will result in a DataFrame containing only rows where 'class' is 'Second'
titanic_filtered = titanic.loc[~titanic['class'].isin(['First', 'Third'])]

# Print the head of the filtered DataFrame to show the result
print(titanic_filtered.head())
```
### 43. df.apply(function, axis=1)
Applies a function along an axis of the DataFrame (e.g., row-wise operations).

```py
import seaborn as sns
import pandas as pd

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Display the first few rows of the original DataFrame
print("Original Titanic DataFrame (first 5 rows):\n", titanic.head())

# Define a function to apply row-wise (axis=1)
# This function categorizes passengers based on their age and fare
def categorize_passenger(row):
    if row['age'] < 18:
        age_category = 'Child'
    elif row['age'] >= 18 and row['age'] < 60:
        age_category = 'Adult'
    else:
        age_category = 'Senior'

    if row['fare'] < 20:
        fare_category = 'Low_Fare'
    elif row['fare'] >= 20 and row['fare'] < 50:
        fare_category = 'Medium_Fare'
    else:
        fare_category = 'High_Fare'

    # Return a Series or dictionary if adding multiple new columns,
    # or a single value if adding one new column.
    # Here, we'll return a string combining both categories for simplicity.
    return f"{age_category}_{fare_category}"

# Apply the function row-wise (axis=1) to create a new column
# The function will receive each row of the DataFrame as a Series.
titanic['Passenger_Category'] = titanic.apply(categorize_passenger, axis=1)

# Display the DataFrame with the new 'Passenger_Category' column
# Showing the relevant columns to demonstrate the effect of apply()
print("\nTitanic DataFrame with 'Passenger_Category' (first 10 rows):\n",
      titanic[['age', 'fare', 'Passenger_Category']].head(10))

# Display some value counts for the new column to verify
print("\nValue counts for 'Passenger_Category':\n", titanic['Passenger_Category'].value_counts())

```

### 44. df.select_dtypes(include='number')
Selects columns based on their data type (e.g., only numeric columns).

```py
import pandas as pd
import seaborn as sns

# Load the titanic dataset
titanic = sns.load_dataset('titanic')

# Select only the numerical columns from the DataFrame
numeric_columns_titanic = titanic.select_dtypes(include='number')

# Display the head of the DataFrame with only numerical columns
print(numeric_columns_titanic.head())
```

### 45. df.drop(['col1', 'col2'], axis=1)
Drops specified columns from the DataFrame.

```py
import seaborn as sns
import pandas as pd # Import pandas to work with DataFrames

# Load the titanic dataset
titanic = sns.load_dataset('titanic')

# Display the original columns before dropping
print("Original DataFrame columns:", titanic.columns.tolist())

# Drop specified columns (e.g., 'deck' and 'alive')
# axis=1 indicates that we are dropping columns, not rows
# inplace=False (default) means it returns a new DataFrame, original remains unchanged
titanic_dropped = titanic.drop(['deck', 'alive'], axis=1)

# Display the columns after dropping
print("\nDataFrame columns after dropping 'deck' and 'alive':", titanic_dropped.columns.tolist())

# Optional: Display the head of the DataFrame to see the effect
print("\nFirst 5 rows of the DataFrame after dropping columns:\n", titanic_dropped.head())

# The request explicitly said "no plotting required here below",
# so no matplotlib or seaborn plotting commands are included.
```

### 46. df.drop(index=[0, 1])
Drops rows by their index labels.

```py
import pandas as pd
import seaborn as sns

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Print the head of the original DataFrame to show initial state
print("Original DataFrame head:\n", titanic.head())

# Drop rows with index labels 0 and 1
titanic_dropped = titanic.drop(index=[0, 1])

# Print the head of the DataFrame after dropping rows to show the effect
print("\nDataFrame head after dropping rows with index 0 and 1:\n", titanic_dropped.head())
```

### 47. df.isnull().sum()
Returns a Series with the count of null values per column.

```py
import seaborn as sns
import pandas as pd # pandas is implicitly needed for DataFrame operations

# Load the titanic dataset
titanic = sns.load_dataset('titanic')

# Calculate the sum of null values for each column
null_counts = titanic.isnull().sum()

# Display the result
print(null_counts)
```

### 48. df.isnull().sum(axis=1)
Returns a Series with the count of null values per row.

```py
import pandas as pd
import seaborn as sns

# Load the Titanic dataset
titanic_df = sns.load_dataset('titanic')

# Calculate the number of null values per row
null_values_per_row = titanic_df.isnull().sum(axis=1)

# Print the result (a Series showing null counts for each row)
print(null_values_per_row)
```

### 49. df.interpolate()
Fills NaN values using interpolation methods (e.g., linear, polynomial).

```py
import seaborn as sns
import pandas as pd

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Before interpolation: Display original DataFrame with NaN values in 'age' column
print("DataFrame before interpolation (Age column):\n", titanic[['age']].head(10))
print("\nNumber of NaN values in 'age' before interpolation:", titanic['age'].isnull().sum())

# Apply interpolation to the 'age' column
# By default, interpolate() uses linear method
titanic['age_interpolated'] = titanic['age'].interpolate()

# After interpolation: Display DataFrame with interpolated 'age' column
print("\nDataFrame after interpolation (Age column):\n", titanic[['age', 'age_interpolated']].head(10))
print("\nNumber of NaN values in 'age_interpolated' after interpolation:", titanic['age_interpolated'].isnull().sum())

# You can also interpolate the entire DataFrame (only numeric columns will be affected)
# This is typically done on a copy to avoid modifying the original DataFrame unintentionally.
# titanic_interpolated_all = titanic.copy().interpolate()
# print("\nDataFrame after interpolating all numeric columns (first 5 rows):\n", titanic_interpolated_all.head())
```

### 50. df.clip(lower=min_val, upper=max_val)
Clips values in the DataFrame to be within a specified range.

```py
import seaborn as sns
import pandas as pd # Import pandas for DataFrame operations

# Load the Titanic dataset
titanic = sns.load_dataset('titanic')

# Define min_val and max_val for a numerical column, for example, 'age'
# Let's say we want to clip age values to be between 10 and 60.
min_age = 10
max_age = 60

# Apply the clip() method to the 'age' column
# This will set any age below 10 to 10, and any age above 60 to 60.
titanic['age_clipped'] = titanic['age'].clip(lower=min_age, upper=max_age)

# Display a comparison of original vs. clipped 'age' values
# Select a few rows that demonstrate the clipping effect if possible,
# or just show head/tail for general overview.
print("Original and Clipped 'age' column comparison:")
print(titanic[['age', 'age_clipped']].head(10))

print("\nDescription of original 'age' column:")
print(titanic['age'].describe())

print("\nDescription of clipped 'age_clipped' column:")
print(titanic['age_clipped'].describe())

# You can also show specific rows to verify clipping
print("\nRows demonstrating clipping:")
# Find rows where age was originally less than min_age or greater than max_age
clipped_rows = titanic[(titanic['age'] < min_age) | (titanic['age'] > max_age)]
print(clipped_rows[['age', 'age_clipped', 'sex']].head(5)) # Display first 5 relevant rows
```



